{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ab403b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pydantic import BaseModel, Field\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.ops import box_convert\n",
    "from tqdm import tqdm\n",
    "\n",
    "from ssd import SSD\n",
    "from ssd.data import LetterboxTransform, SSDDataset\n",
    "from ssd.structs import FrameLabels\n",
    "from ssd.utils import TrainUtils\n",
    "from ssd.utils.metrics_calculator import MetricsCalculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e711b65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluateConfig(BaseModel):\n",
    "    images_dir: Path\n",
    "    labels_dir: Path\n",
    "    min_confidence_threshold: float = Field(default=0.1)\n",
    "    num_top_k: int = Field(default=100)\n",
    "    nms_iou_threshold: float = Field(default=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8c635c",
   "metadata": {},
   "source": [
    "### Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbf6787",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda:0\")\n",
    "CONFIG = EvaluateConfig(\n",
    "    images_dir=Path(\"/mnt/data/datasets/object_detection/coco/images/val2017\"),\n",
    "    labels_dir=Path(\"/mnt/data/datasets/object_detection/coco/labels/val2017\"),\n",
    "    min_confidence_threshold=0.1,\n",
    "    num_top_k=200,\n",
    "    nms_iou_threshold=0.2,\n",
    ")\n",
    "\n",
    "MODEL_FILE = Path(\n",
    "    \"/mnt/data/code/ssd/runs/ea4e4832-f3ec-4aef-8a65-d4badf2bb9c8/best.pt\"\n",
    ")\n",
    "IMAGE_WIDTH = 300\n",
    "IMAGE_HEIGHT = 300\n",
    "DTYPE = torch.float32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c56baa",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4560c761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model in\n",
    "model = SSD.load(MODEL_FILE, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a035a9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = LetterboxTransform(IMAGE_WIDTH, IMAGE_HEIGHT, DTYPE)\n",
    "collate_func = partial(TrainUtils.batch_collate_func, device=DEVICE)\n",
    "\n",
    "dataset = SSDDataset(\n",
    "    CONFIG.images_dir,\n",
    "    CONFIG.labels_dir,\n",
    "    model.num_classes,\n",
    "    transform,\n",
    "    None,\n",
    "    DEVICE,\n",
    "    DTYPE,\n",
    ")\n",
    "data_loader = DataLoader(dataset, 8, shuffle=True, collate_fn=collate_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff1e6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "images: Tensor\n",
    "frame_labels: list[FrameLabels]\n",
    "metrics_calculator = MetricsCalculator(model.num_classes)\n",
    "image_detections: list[dict[str, Tensor]] = []\n",
    "image_labels: list[dict[str, Tensor]] = []\n",
    "for images, frame_labels in tqdm(data_loader):\n",
    "    with torch.no_grad():\n",
    "        head_outputs, anchors = model.forward(images)\n",
    "        frame_detections = model._post_process_detections(\n",
    "            head_outputs,\n",
    "            anchors,\n",
    "            CONFIG.min_confidence_threshold,\n",
    "            CONFIG.num_top_k,\n",
    "            CONFIG.nms_iou_threshold,\n",
    "        )\n",
    "\n",
    "        metrics_calculator.update(frame_detections, frame_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2cde38",
   "metadata": {},
   "source": [
    "### Analyse per-class metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6a736b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_ID = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf934e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the precision\n",
    "precisions = metrics_calculator.precisions()[:, :, CLASS_ID]\n",
    "precisions = precisions.cpu().numpy()\n",
    "\n",
    "plt.figure()\n",
    "for iou_idx in range(precisions.shape[1]):\n",
    "    plt.plot(\n",
    "        metrics_calculator._confidence_thresholds,\n",
    "        precisions[:, iou_idx],\n",
    "        label=f\"IoU thresh = {metrics_calculator._iou_thresholds[iou_idx]:.2f}\",\n",
    "    )\n",
    "plt.xlim((0, 1))\n",
    "plt.ylim((0, 1))\n",
    "plt.title(f\"Precision with confidence\\nclass_id={CLASS_ID}\")\n",
    "plt.xlabel(\"Confidence threshold\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e1b1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the recall\n",
    "recalls = metrics_calculator.recalls()[:, :, CLASS_ID]\n",
    "recalls = recalls.cpu().numpy()\n",
    "\n",
    "plt.figure()\n",
    "for iou_idx in range(precisions.shape[1]):\n",
    "    plt.plot(\n",
    "        metrics_calculator._confidence_thresholds,\n",
    "        recalls[:, iou_idx],\n",
    "        label=f\"IoU thresh = {metrics_calculator._iou_thresholds[iou_idx]:.2f}\",\n",
    "    )\n",
    "plt.xlim((0, 1))\n",
    "plt.ylim((0, 1))\n",
    "plt.title(f\"Recall with confidence\\nclass_id={CLASS_ID}\")\n",
    "plt.xlabel(\"Confidence threshold\")\n",
    "plt.ylabel(\"Recall\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ac5ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the PR-curve\n",
    "plt.figure()\n",
    "for iou_idx in range(precisions.shape[1]):\n",
    "    plt.plot(\n",
    "        recalls[:, iou_idx],\n",
    "        precisions[:, iou_idx],\n",
    "        label=f\"IoU thresh = {metrics_calculator._iou_thresholds[iou_idx]:.2f}\",\n",
    "    )\n",
    "plt.xlim((0, 1))\n",
    "plt.ylim((0, 1))\n",
    "plt.title(f\"Precision-recall curve\\nclass_id={CLASS_ID}\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94bd1ac",
   "metadata": {},
   "source": [
    "### Analyse overall accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee290c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mAPs = metrics_calculator.mAPs().cpu().numpy()\n",
    "\n",
    "plt.figure()\n",
    "class_ids = [cid for cid in range(model.num_classes)]\n",
    "plt.bar(class_ids, mAPs)\n",
    "plt.xlabel(\"Class ID\")\n",
    "plt.ylabel(\"mAP@(50-95)\")\n",
    "plt.grid()\n",
    "plt.xlim((0, model.num_classes))\n",
    "plt.ylim((0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4653e284",
   "metadata": {},
   "outputs": [],
   "source": [
    "mAPs.mean().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d13ed2",
   "metadata": {},
   "source": [
    "### Visualise detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd438d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_colours = [\n",
    "    (np.random.randint(0, 255), np.random.randint(0, 255), np.random.randint(0, 255))\n",
    "    for _ in range(80)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5eb1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "images: Tensor\n",
    "objects: list[FrameLabels]\n",
    "images, objects = next(iter(data_loader))\n",
    "with torch.no_grad():\n",
    "    head_outputs, anchors = model.forward(images)\n",
    "    frame_detections = model._post_process_detections(\n",
    "        head_outputs,\n",
    "        anchors,\n",
    "        CONFIG.min_confidence_threshold,\n",
    "        CONFIG.num_top_k,\n",
    "        CONFIG.nms_iou_threshold,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88fcc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display labels\n",
    "num_rows = 2\n",
    "num_cols = images.shape[0] // num_rows\n",
    "fig, axes = plt.subplots(num_rows, num_cols)\n",
    "fig.set_figwidth(16)\n",
    "fig.set_figheight(8)\n",
    "for idx in range(images.shape[0]):\n",
    "    row = idx // num_cols\n",
    "    col = idx % num_cols\n",
    "\n",
    "    # Extract the image\n",
    "    image = images[idx, ...].permute((1, 2, 0)).clone()\n",
    "    image *= 255\n",
    "    image = image.to(torch.uint8).cpu().numpy().copy()\n",
    "\n",
    "    # Draw the detections on the image\n",
    "    objs = objects[idx]\n",
    "    boxes = box_convert(objs.boxes, \"cxcywh\", \"xyxy\")\n",
    "    boxes[:, ::2] *= IMAGE_WIDTH\n",
    "    boxes[:, 1::2] *= IMAGE_HEIGHT\n",
    "    boxes = boxes.cpu().to(torch.int).numpy()\n",
    "    class_ids = objs.class_ids.cpu().to(torch.int).numpy()\n",
    "\n",
    "    for box_idx in range(boxes.shape[0]):\n",
    "        box = boxes[box_idx, :]\n",
    "        class_id = class_ids[box_idx]\n",
    "        image = cv2.rectangle(\n",
    "            image, tuple(box[:2]), tuple(box[2:]), class_colours[class_id], 2\n",
    "        )\n",
    "        cv2.putText(\n",
    "            image, f\"c={class_id}\", tuple(box[:2]), 0, 0.6, class_colours[class_id], 2\n",
    "        )\n",
    "\n",
    "    axes[row, col].imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368cafdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display detections\n",
    "num_rows = 2\n",
    "num_cols = images.shape[0] // num_rows\n",
    "fig, axes = plt.subplots(num_rows, num_cols)\n",
    "fig.set_figwidth(16)\n",
    "fig.set_figheight(8)\n",
    "for idx in range(images.shape[0]):\n",
    "    row = idx // num_cols\n",
    "    col = idx % num_cols\n",
    "\n",
    "    # Extract the image\n",
    "    image = images[idx, ...].permute((1, 2, 0)).clone()\n",
    "    image *= 255\n",
    "    image = image.to(torch.uint8).cpu().numpy().copy()\n",
    "\n",
    "    # Draw the detections on the image\n",
    "    detections = frame_detections[idx]\n",
    "    boxes = box_convert(detections.boxes, \"cxcywh\", \"xyxy\")\n",
    "    boxes[:, ::2] *= IMAGE_WIDTH\n",
    "    boxes[:, 1::2] *= IMAGE_HEIGHT\n",
    "    boxes = boxes.cpu().to(torch.int).numpy()\n",
    "    class_ids = detections.class_ids.cpu().to(torch.int).numpy()\n",
    "\n",
    "    for box_idx in range(boxes.shape[0]):\n",
    "        box = boxes[box_idx, :]\n",
    "        class_id = class_ids[box_idx]\n",
    "        image = cv2.rectangle(\n",
    "            image, tuple(box[:2]), tuple(box[2:]), class_colours[class_id], 2\n",
    "        )\n",
    "        cv2.putText(\n",
    "            image, f\"c={class_id}\", tuple(box[:2]), 0, 0.6, class_colours[class_id], 2\n",
    "        )\n",
    "\n",
    "    axes[row, col].imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd25810",
   "metadata": {},
   "outputs": [],
   "source": [
    "images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4872d46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssd-3.11 (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
